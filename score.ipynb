{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rPOYQuAnZ8ub",
        "outputId": "6d2c8f1b-8b54-4311-e23d-60fd1a1bac66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HUGGINGFACE_TOKEN set (length): 37\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"HF_HOME\"] = \"/content/hf\"\n",
        "os.environ[\"HUGGINGFACE_TOKEN\"] = HF_TOKEN\n",
        "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
        "print(\"HUGGINGFACE_TOKEN set (length):\", len(HF_TOKEN))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yunx-z/SCORE.git\n",
        "%cd SCORE\n",
        "!ls -l\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1usDVSmag2w",
        "outputId": "cd09033d-1c0b-47d5-8480-0169cf876a39",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SCORE'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 54 (delta 17), reused 54 (delta 17), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (54/54), 1.77 MiB | 5.57 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n",
            "/content/SCORE\n",
            "total 224\n",
            "-rw-r--r-- 1 root root  6372 Dec 28 14:55 apply_feedback.py\n",
            "-rw-r--r-- 1 root root  4120 Dec 28 14:55 apply_feedback_results.py\n",
            "-rw-r--r-- 1 root root  3047 Dec 28 14:55 create_verifier_ft_data.py\n",
            "drwxr-xr-x 5 root root  4096 Dec 28 14:55 data\n",
            "-rw-r--r-- 1 root root  1748 Dec 28 14:55 eval_deciding_refinement.py\n",
            "-rw-r--r-- 1 root root 22554 Dec 28 14:55 ft_results.py\n",
            "-rw-r--r-- 1 root root  3733 Dec 28 14:55 llama_inference.py\n",
            "-rw-r--r-- 1 root root 15155 Dec 28 14:55 llama_sequence_classification.py\n",
            "-rw-r--r-- 1 root root 14568 Dec 28 14:55 pal_code_exec.py\n",
            "-rw-r--r-- 1 root root  9089 Dec 28 14:55 prefilter_feedback.py\n",
            "-rw-r--r-- 1 root root  2263 Dec 28 14:55 prepare_predict_rationale_data.py\n",
            "-rw-r--r-- 1 root root 33499 Dec 28 14:55 prepare_sft_data.py\n",
            "-rw-r--r-- 1 root root  6186 Dec 28 14:55 python_executor.py\n",
            "-rw-r--r-- 1 root root  7945 Dec 28 14:55 README.md\n",
            "-rw-r--r-- 1 root root    92 Dec 28 14:55 requirements.txt\n",
            "-rw-r--r-- 1 root root  5305 Dec 28 14:55 rerank.py\n",
            "-rw-r--r-- 1 root root  5620 Dec 28 14:55 sample_ans.py\n",
            "-rw-r--r-- 1 root root 10234 Dec 28 14:55 sample_feedback.py\n",
            "-rw-r--r-- 1 root root  5620 Dec 28 14:55 sample_refinement.py\n",
            "-rw-r--r-- 1 root root  9065 Dec 28 14:55 sample_verification.py\n",
            "-rw-r--r-- 1 root root 14793 Dec 28 14:55 util.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install transformers accelerate datasets evaluate bitsandbytes\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aOn9-25SCs_",
        "outputId": "4df68dbf-dc7b-466a-8652-8bd6f95893f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==2.14.5 (from -r requirements.txt (line 1))\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting tenacity==8.2.3 (from -r requirements.txt (line 2))\n",
            "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.13.1+cu117 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0, 2.9.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.13.1+cu117\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes, evaluate\n",
            "Successfully installed bitsandbytes-0.49.0 evaluate-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TASK\"] = \"gsm8k_nl\"\n",
        "os.environ[\"MODEL\"] = \"google/gemma-2b-it\"\n",
        "\n",
        "print(\"TASK =\", os.environ[\"TASK\"])\n",
        "print(\"MODEL =\", os.environ[\"MODEL\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpNHynRaaDju",
        "outputId": "4b18a7ab-722f-430c-cd44-dcc7bbaaaa54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TASK = gsm8k_nl\n",
            "MODEL = google/gemma-2b-it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pal_code_exec.py --task ${TASK} --model ${MODEL} --split test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0gLenmJc-fM",
        "outputId": "65aad61b-de31-4766-c7ec-ed10bbe692bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logs/gsm8k_nl/generations_google-gemma-2b-it_score_test.jsonl\n",
            "top1 accu: 11.45\n",
            "0-th accu: 11.45\n",
            "avg accu@1: 11.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python sample_ans.py --task $TASK --model $MODEL --split test --num_generations 1\n"
      ],
      "metadata": {
        "id": "r_uDemCHaqg6",
        "outputId": "42dddf95-a290-4a5c-cdea-d3eb0e5131d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-22 19:59:01.506218: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766433541.525474     926 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766433541.531539     926 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766433541.546283     926 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766433541.546310     926 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766433541.546313     926 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766433541.546316     926 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-22 19:59:01.550914: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/content/SCORE/util.py:118: SyntaxWarning: invalid escape sequence '\\['\n",
            "  input_str_cleaned = re.sub(\"(\\[END|\\[|END)$\", \"\", input_str_cleaned)\n",
            "/content/SCORE/util.py:130: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  all_numbers = [re.sub(r\"[^0-9.]\", \"\", n) for n in re.findall(\"[0-9,]*\\.?[0-9,]+\", re.sub(\"Step \\d+:\", \"\", input_str))]\n",
            "/content/SCORE/util.py:130: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  all_numbers = [re.sub(r\"[^0-9.]\", \"\", n) for n in re.findall(\"[0-9,]*\\.?[0-9,]+\", re.sub(\"Step \\d+:\", \"\", input_str))]\n",
            "/content/SCORE/util.py:135: SyntaxWarning: invalid escape sequence '\\('\n",
            "  all_choices = re.findall(\"\\(([A-Z])\\)\", input_str)\n",
            "tokenizer_config.json: 100% 34.2k/34.2k [00:00<00:00, 88.2MB/s]\n",
            "tokenizer.model: 100% 4.24M/4.24M [00:01<00:00, 3.91MB/s]\n",
            "tokenizer.json: 100% 17.5M/17.5M [00:00<00:00, 39.4MB/s]\n",
            "special_tokens_map.json: 100% 636/636 [00:00<00:00, 5.46MB/s]\n",
            "config.json: 100% 627/627 [00:00<00:00, 4.99MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "model.safetensors.index.json: 100% 13.5k/13.5k [00:00<00:00, 60.2MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/67.1M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.95G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   0% 40.9k/67.1M [00:01<27:50, 40.2kB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 67.1M/67.1M [00:01<00:00, 45.2MB/s]\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 42.3M/4.95G [00:02<03:59, 20.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 109M/4.95G [00:03<02:43, 29.6MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 128M/4.95G [00:04<02:31, 31.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 153M/4.95G [00:04<01:57, 40.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 220M/4.95G [00:05<01:18, 59.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   6% 320M/4.95G [00:05<00:39, 117MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   8% 404M/4.95G [00:05<00:31, 146MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  10% 471M/4.95G [00:05<00:27, 165MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  11% 538M/4.95G [00:06<00:22, 200MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  13% 623M/4.95G [00:07<00:32, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  14% 690M/4.95G [00:07<00:31, 134MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  15% 740M/4.95G [00:08<00:33, 127MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  16% 807M/4.95G [00:08<00:39, 106MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  18% 874M/4.95G [00:09<00:36, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  19% 941M/4.95G [00:10<00:34, 115MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/4.95G [00:10<00:30, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  22% 1.07G/4.95G [00:10<00:25, 153MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/4.95G [00:14<01:21, 46.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  26% 1.28G/4.95G [00:14<00:47, 76.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  27% 1.34G/4.95G [00:15<00:38, 93.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  29% 1.41G/4.95G [00:15<00:31, 113MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.95G [00:15<00:29, 116MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  34% 1.68G/4.95G [00:16<00:15, 212MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  35% 1.75G/4.95G [00:16<00:14, 215MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 1.81G/4.95G [00:18<00:33, 94.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  39% 1.95G/4.95G [00:18<00:21, 140MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  41% 2.01G/4.95G [00:24<01:12, 40.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/4.95G [00:24<00:45, 61.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  45% 2.22G/4.95G [00:25<00:35, 76.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.95G [00:25<00:29, 91.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  48% 2.35G/4.95G [00:25<00:25, 103MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  49% 2.42G/4.95G [00:26<00:20, 123MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  50% 2.48G/4.95G [00:26<00:17, 141MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  52% 2.55G/4.95G [00:26<00:14, 163MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  53% 2.62G/4.95G [00:26<00:13, 177MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 2.68G/4.95G [00:27<00:11, 188MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  56% 2.76G/4.95G [00:27<00:10, 212MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  57% 2.83G/4.95G [00:27<00:09, 228MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  59% 2.90G/4.95G [00:27<00:08, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  60% 2.98G/4.95G [00:29<00:15, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  61% 3.03G/4.95G [00:29<00:13, 137MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  63% 3.10G/4.95G [00:30<00:15, 121MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  64% 3.17G/4.95G [00:34<00:48, 36.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/4.95G [00:35<00:33, 51.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  66% 3.26G/4.95G [00:35<00:29, 57.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  67% 3.33G/4.95G [00:35<00:21, 76.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  69% 3.42G/4.95G [00:35<00:14, 106MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  71% 3.49G/4.95G [00:36<00:11, 127MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  72% 3.56G/4.95G [00:36<00:09, 151MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  73% 3.60G/4.95G [00:36<00:08, 160MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  74% 3.67G/4.95G [00:36<00:06, 190MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  76% 3.74G/4.95G [00:37<00:05, 211MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 3.81G/4.95G [00:37<00:05, 206MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.95G [00:37<00:04, 220MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  80% 3.94G/4.95G [00:37<00:04, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  81% 4.01G/4.95G [00:38<00:03, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  82% 4.07G/4.95G [00:38<00:03, 241MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  84% 4.14G/4.95G [00:38<00:03, 238MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 4.21G/4.95G [00:39<00:03, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  86% 4.27G/4.95G [00:39<00:03, 217MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  88% 4.34G/4.95G [00:39<00:02, 270MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  89% 4.41G/4.95G [00:39<00:01, 269MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  91% 4.48G/4.95G [00:40<00:01, 258MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  92% 4.54G/4.95G [00:40<00:01, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  93% 4.61G/4.95G [00:41<00:03, 108MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  95% 4.68G/4.95G [00:45<00:05, 46.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  97% 4.81G/4.95G [00:45<00:01, 79.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  99% 4.88G/4.95G [00:45<00:00, 97.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors: 100% 4.95G/4.95G [00:45<00:00, 108MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:46<00:00, 23.14s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:12<00:00,  6.28s/it]\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 989kB/s]\n",
            "logs/gsm8k_nl/generations_google-gemma-2b-it_0_-1_test.jsonl\n",
            "100% 1319/1319 [2:47:31<00:00,  7.62s/it]\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ft_results.py --task ${TASK} --stage eval_greedy_refine --input prompted --verifier_type ours_ft_on_prompted_solutions --verifier_model ${MODEL} --refiner_type filtered_feedback4_refinement_diff --refiner_model ${MODEL} --split test --best_dev_confidence ${THRESHOLD} --verbose\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP8FqsR5QTK7",
        "outputId": "f6c1f8dc-b39e-45ba-fe44-eb1dcd753372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top1 accu: 21.45\n",
            "0-th accu: 20.13\n",
            "avg accu@1: 20.79\n"
          ]
        }
      ]
    }
  ]
}